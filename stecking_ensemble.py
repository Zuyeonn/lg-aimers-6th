import pandas as pd
import numpy as np
from sklearn.preprocessing import OrdinalEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from sklearn.linear_model import LogisticRegression  

# =======================================
# XGBoost ì „ì²˜ë¦¬ (ìˆ˜ì¹˜í˜• ê²°ì¸¡ì¹˜ëŠ” ì¤‘ì•™ê°’ ì²˜ë¦¬)
# =======================================
def preprocess_xgb():
    print("XGBoost ì „ì²˜ë¦¬ ì‹œì‘...")
    
    train = pd.read_csv("train.csv")
    test = pd.read_csv("test.csv")
    train.drop(columns=['ID'], inplace=True)
    test.drop(columns=['ID'], inplace=True)
    
    # í•™ìŠµ ë°ì´í„°ì—ì„œ ì œì™¸ ì»¬ëŸ¼
    drop_columns = ['ì„ì‹  ì„±ê³µ ì—¬ë¶€', 'PGD ì‹œìˆ  ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', 'ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸', 'ë‚œì ì±„ì·¨ ê²½ê³¼ì¼']
    X = train.drop(columns=drop_columns)
    y = train['ì„ì‹  ì„±ê³µ ì—¬ë¶€']
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•œ í”¼ì²˜ ì§‘í•©ìœ¼ë¡œ ì¬ì •ë ¬ (ì—†ëŠ” ì»¬ëŸ¼ì€ -1ë¡œ ì±„ì›€)
    test = test.reindex(columns=X.columns, fill_value=-1)
    
    categorical_columns = [
        "ì‹œìˆ  ì‹œê¸° ì½”ë“œ", "ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´", "ì‹œìˆ  ìœ í˜•", "íŠ¹ì • ì‹œìˆ  ìœ í˜•", "ë°°ë€ ìê·¹ ì—¬ë¶€", "ë°°ë€ ìœ ë„ ìœ í˜•", 
        "ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€", "ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€", "ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸", "ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸", 
        "ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸", "ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸", "ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸", "ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸", "ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸", 
        "ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜", "ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸", "ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• ", "ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ", 
        "ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦", "ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„", "ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸", "ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±", 
        "ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ", "ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ", "ì´ ì‹œìˆ  íšŸìˆ˜", "í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜", "IVF ì‹œìˆ  íšŸìˆ˜", 
        "DI ì‹œìˆ  íšŸìˆ˜", "ì´ ì„ì‹  íšŸìˆ˜", "IVF ì„ì‹  íšŸìˆ˜", "DI ì„ì‹  íšŸìˆ˜", "ì´ ì¶œì‚° íšŸìˆ˜", "IVF ì¶œì‚° íšŸìˆ˜", 
        "DI ì¶œì‚° íšŸìˆ˜", "ë‚œì ì¶œì²˜", "ì •ì ì¶œì²˜", "ë‚œì ê¸°ì¦ì ë‚˜ì´", "ì •ì ê¸°ì¦ì ë‚˜ì´", "ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", 
        "ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ëŒ€ë¦¬ëª¨ ì—¬ë¶€", "PGS ì‹œìˆ  ì—¬ë¶€"
    ]
    numeric_columns = [
        "ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜", "ì´ ìƒì„± ë°°ì•„ ìˆ˜", "ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜", "ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜", 
        "ì´ì‹ëœ ë°°ì•„ ìˆ˜", "ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜", "ì €ì¥ëœ ë°°ì•„ ìˆ˜", "ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜", "í•´ë™ëœ ë°°ì•„ ìˆ˜", 
        "í•´ë™ ë‚œì ìˆ˜", "ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜", "ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜", "í˜¼í•©ëœ ë‚œì ìˆ˜", "íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜", 
        "ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜", "ë‚œì í•´ë™ ê²½ê³¼ì¼", "ë‚œì í˜¼í•© ê²½ê³¼ì¼", "ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼", "ë°°ì•„ í•´ë™ ê²½ê³¼ì¼"
    ]
    
    # ë²”ì£¼í˜• ë³€ìˆ˜: ë¬¸ìì—´ ë³€í™˜ í›„ Ordinal Encoding
    for col in categorical_columns:
        X[col] = X[col].astype(str)
        test[col] = test[col].astype(str)
    ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
    X[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])
    test[categorical_columns] = ordinal_encoder.transform(test[categorical_columns])
    
    # ìˆ˜ì¹˜í˜• ê²°ì¸¡ì¹˜ëŠ” 0 ëŒ€ì‹  ê° ì»¬ëŸ¼ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ì±„ì›€
    for col in numeric_columns:
        median_val = X[col].median()
        X[col] = X[col].fillna(median_val)
        test[col] = test[col].fillna(median_val)
    
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
    
    print("XGBoost ì „ì²˜ë¦¬ ì™„ë£Œ")
    return X_train, X_val, y_train, y_val, test
    
    
# ======================================
#  CatBoost ì „ì²˜ë¦¬ (ìˆ˜ì¹˜í˜• ê²°ì¸¡ì¹˜ëŠ” ì¤‘ì•™ê°’ ì²˜ë¦¬)
# ======================================
def preprocess_cat():
    print("CatBoost ì „ì²˜ë¦¬ ì‹œì‘...")
    train_data = pd.read_csv("train.csv", encoding='utf-8')
    test_data = pd.read_csv("test.csv", encoding='utf-8')
    sample_submission = pd.read_csv("sample_submission.csv", encoding='utf-8')
    
    # í•™ìŠµì— ì œì™¸í•  ì»¬ëŸ¼ ì„¤ì •
    exclude_cols = [
        "ë‚œì í•´ë™ ê²½ê³¼ì¼",
        "PGS ì‹œìˆ  ì—¬ë¶€",
        "PGD ì‹œìˆ  ì—¬ë¶€",
        "ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬(PGS) ì‚¬ìš© ì—¬ë¶€",
        "ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨(PGD) ì‚¬ìš© ì—¬ë¶€",
        "ë‚œì ê¸°ì¦ì ë‚˜ì´",
        "ì •ì ê¸°ì¦ì ë‚˜ì´"
    ]
    id_col = "ID"
    target_col = "ì„ì‹  ì„±ê³µ ì—¬ë¶€"
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°: ID ë³´ì¡´ í›„ ì œì™¸í•  ì»¬ëŸ¼ ì œê±°
    test_ids = test_data[id_col].values
    X_test = test_data.drop(id_col, axis=1)
    drop_cols_test = [col for col in exclude_cols if col in X_test.columns]
    X_test = X_test.drop(drop_cols_test, axis=1)
    
    # í•™ìŠµ ë°ì´í„°: íƒ€ê¹ƒ ë° ID, ì œì™¸í•  ì»¬ëŸ¼ ì œê±°
    X = train_data.drop(target_col, axis=1)
    y = train_data[target_col]
    if id_col in X.columns:
        X = X.drop(id_col, axis=1)
    drop_cols_train = [col for col in exclude_cols if col in X.columns]
    X = X.drop(drop_cols_train, axis=1)
    
    # CatBoostì—ì„œ ì‚¬ìš©í•  ë²”ì£¼í˜• ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸
    cat_features = [
        "ì‹œìˆ  ì‹œê¸° ì½”ë“œ", "ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´", "ì‹œìˆ  ìœ í˜•", "íŠ¹ì • ì‹œìˆ  ìœ í˜•", "ë°°ë€ ìê·¹ ì—¬ë¶€", "ë°°ë€ ìœ ë„ ìœ í˜•", 
        "ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€", "ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸", "ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸", "ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸", "ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸", 
        "ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸", "ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸", "ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸", "ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜", "ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸", 
        "ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• ", "ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸", "ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ", "ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦", 
        "ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„", "ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸", "ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±", "ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ", 
        "ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ", "ì´ ì‹œìˆ  íšŸìˆ˜", "í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜", "IVF ì‹œìˆ  íšŸìˆ˜", "DI ì‹œìˆ  íšŸìˆ˜", 
        "ì´ ì„ì‹  íšŸìˆ˜", "IVF ì„ì‹  íšŸìˆ˜", "DI ì„ì‹  íšŸìˆ˜", "ì´ ì¶œì‚° íšŸìˆ˜", "IVF ì¶œì‚° íšŸìˆ˜", "DI ì¶œì‚° íšŸìˆ˜", 
        "ë‚œì ì¶œì²˜", "ì •ì ì¶œì²˜", "ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ëŒ€ë¦¬ëª¨ ì—¬ë¶€"
    ]
    
    # ë²”ì£¼í˜• ë³€ìˆ˜: ë¬¸ìì—´ ë³€í™˜
    for col in cat_features:
        if col in X.columns:
            X[col] = X[col].astype(str)
        if col in X_test.columns:
            X_test[col] = X_test[col].astype(str)
    
    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼: ê²°ì¸¡ì¹˜ëŠ” ê° ì»¬ëŸ¼ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´
    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()
    for col in numeric_cols:
        median_val = X[col].median()
        X[col] = X[col].fillna(median_val)
        if col in X_test.columns:
            X_test[col] = X_test[col].fillna(median_val)
    
    # ë²”ì£¼í˜• ì»¬ëŸ¼: ê²°ì¸¡ì¹˜ëŠ” "missing" ì²˜ë¦¬
    for col in X.columns:
        if X[col].dtype == 'object':
            X[col] = X[col].fillna("missing")
    for col in X_test.columns:
        if X_test[col].dtype == 'object':
            X_test[col] = X_test[col].fillna("missing")
    
    # Train/Validation Split (80:20, random_state ê³ ì •)
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)
    
    # í•™ìŠµ ë° ê²€ì¦ ë°ì´í„°ì˜ ë²”ì£¼í˜• ë³€ìˆ˜ íƒ€ì… ë³´ì¥
    for col in cat_features:
        if col in X_train.columns:
            X_train[col] = X_train[col].astype(str)
        if col in X_val.columns:
            X_val[col] = X_val[col].astype(str)
    
    print("CatBoost ì „ì²˜ë¦¬ ì™„ë£Œ.")
    return X_train, X_val, y_train, y_val, X_test, test_ids, cat_features
    


# =====================
#  Stacking 
# =====================

# ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰
X_train_xgb, X_valid_xgb, y_train, y_valid, X_test_xgb = preprocess_xgb()
X_train_cat, X_valid_cat, y_train_cat, y_valid_cat, X_test_cat, test_ids, cat_features = preprocess_cat()

# ê°œë³„ ëª¨ë¸ í•™ìŠµ (XGBoost & CatBoost)
print("XGBoost ëª¨ë¸ í•™ìŠµ ì¤‘...")
xgb_model = XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6, 
                          subsample=0.8, colsample_bytree=0.8, gamma=0.1, 
                          reg_lambda=1.0, reg_alpha=0.5, eval_metric="logloss", 
                          random_state=42)
xgb_model.fit(X_train_xgb, y_train)
xgb_valid_preds = xgb_model.predict_proba(X_valid_xgb)[:, 1]
xgb_test_preds = xgb_model.predict_proba(X_test_xgb)[:, 1]

print("CatBoost ëª¨ë¸ í•™ìŠµ ì¤‘...")
cat_model = CatBoostClassifier(iterations=500, learning_rate=0.05, depth=6, 
                               l2_leaf_reg=3.0, random_seed=42, verbose=0)
cat_model.fit(X_train_cat, y_train, cat_features=cat_features)
cat_valid_preds = cat_model.predict_proba(X_valid_cat)[:, 1]
cat_test_preds = cat_model.predict_proba(X_test_cat)[:, 1]

# Meta Model í•™ìŠµ (Logistic Regression)
train_meta = np.column_stack((xgb_valid_preds, cat_valid_preds))
test_meta = np.column_stack((xgb_test_preds, cat_test_preds))

print("ë©”íƒ€ ëª¨ë¸(Logistic Regression) í•™ìŠµ ì¤‘...")
meta_model = LogisticRegression()  
meta_model.fit(train_meta, y_valid)
meta_valid_proba = meta_model.predict_proba(train_meta)[:, 1]
meta_test_proba = meta_model.predict_proba(test_meta)[:, 1]  # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¶”ê°€

# í‰ê°€
xgb_roc_auc = roc_auc_score(y_valid, xgb_valid_preds)
cat_roc_auc = roc_auc_score(y_valid, cat_valid_preds)
meta_roc_auc = roc_auc_score(y_valid, meta_valid_proba)

print(f"ğŸ”¹ XGBoost ROC-AUC Score: {xgb_roc_auc:.4f}")
print(f"ğŸ”¹ CatBoost ROC-AUC Score: {cat_roc_auc:.4f}")
print(f"âœ… Meta Model (Stacking - Logistic Regression) ROC-AUC Score: {meta_roc_auc:.4f}")

# í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ë° ì €ì¥
submission = pd.DataFrame({
    "ID": test_ids,  # ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ID ì‚¬ìš©
    "probability": meta_test_proba  # ë©”íƒ€ ëª¨ë¸ì˜ í™•ë¥ ê°’ì„ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì €ì¥
})
submission.to_csv("submission_stacking_logreg.csv", index=False, encoding='utf-8')

print("âœ… ì œì¶œ ì™„ë£Œ: submission_stacking_logreg.csv")
